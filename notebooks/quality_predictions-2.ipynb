{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This messy notebook trains the XGboost model used in wikidit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import wikidit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import _load_backlog, WP10_LABELS\n",
    "from wikidit.io import read_labeled\n",
    "from wikidit.ordinal import SequentialClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/enwiki-labeling_revisions-w_features/\"\n",
    "revisions = read_labeled(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import xgboost as xgb\n",
    "import dill\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, Binarizer\n",
    "\n",
    "count_cols = ['words',\n",
    "             # infobox as a binary\n",
    "             'backlog_accuracy',\n",
    "             'backlog_content',\n",
    "             'backlog_other',\n",
    "             'backlog_style',\n",
    "             'backlog_links']\n",
    "\n",
    "per_word_cols = [\n",
    "             'headings_per_word',\n",
    "             'sub_headings_per_word',\n",
    "             # links\n",
    "             'images_per_word',\n",
    "             'categories_per_word',\n",
    "             'wikilinks_per_word',\n",
    "             'external_links_per_word',\n",
    "             # templates\n",
    "             'main_templates_per_word',\n",
    "             'cite_templates_per_word',\n",
    "             'ref_per_word'    \n",
    "]\n",
    "\n",
    "binarized_cols = ['coordinates', 'infoboxes']\n",
    "\n",
    "response_col = ['wp10']\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    for c in count_cols:\n",
    "        df[c] = np.sqrt(df[c])\n",
    "    for c in binarized_cols:\n",
    "        df[c] = df[c].astype(bool)\n",
    "    allcols = list(itertools.chain(per_word_cols, count_cols, binarized_cols))\n",
    "    return df.loc[:, allcols]\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (count_cols, FunctionTransformer(func=np.sqrt, validate=False)),\n",
    "    (binarized_cols, Binarizer()),\n",
    "    (per_word_cols, None)\n",
    "])\n",
    "\n",
    "X = revisions\n",
    "y = revisions['wp10'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import (f1_score, roc_auc_score, accuracy_score, \n",
    "                             precision_score, recall_score, log_loss, \n",
    "                             confusion_matrix)\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "  'silent': True,\n",
    "  'booster': 'gbtree',\n",
    "  'objective': 'binary:logistic',\n",
    "  'random_state': 12345,\n",
    "  'learning_rate': 0.1,\n",
    "  'n_estimators': 200,\n",
    "  'min_child_weight': 1,\n",
    "  'gamma': 0,\n",
    "  'subsample': 0.9,\n",
    "  'colsample_bytree': 0.9,\n",
    "  'max_depth': 6\n",
    "}\n",
    "# xgb_param_grid = {\n",
    "#    'min_child_weight': list(range(1, 11)),\n",
    "#    'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#    'max_depth': [2, 3, 4, 5, 6, 7, 8]\n",
    "# }\n",
    "\n",
    "clf = SequentialClassifier(xgb.XGBClassifier(**xgb_params))\n",
    "pipeline = Pipeline([('mapper', mapper), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3a47aa7eaac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/insight/wikidit/wikidit/ordinal.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, categories)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 delayed(_parallel_fit_estimator)(clone(self.estimator),\n\u001b[1;32m     37\u001b[0m                                                  X, y, cat)\n\u001b[0;32m---> 38\u001b[0;31m                 for cat in categories)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_estimators_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/insight/wikidit/wikidit/ordinal.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[0;34m(estimator, X, y, cat)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtouse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtouse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtouse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSequentialClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseComposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[1;32m    545\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1021\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitted = clone(pipeline).fit(revisions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/xgboost-sequential.pkl\", \"wb\") as f:\n",
    "    dill.dump(fitted, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to check that things are working with live API data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import Featurizer\n",
    "from wikidit.mw import get_page, Session\n",
    "featurizer = Featurizer()\n",
    "session = Session()\n",
    "page = get_page(session, 'Correlation')\n",
    "revision = featurizer.parse_content(page['content'])\n",
    "del revision['text']\n",
    "revision = pd.DataFrame.from_records([revision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import predict_page_edits\n",
    "results = predict_page_edits(featurizer, page['content'], fitted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#from sklearn.decomposition import PCA\n",
    "#pipeline = Pipeline([('mapper', mapper), \n",
    "#                     ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                     ('var', VarianceThreshold()),\n",
    "#                     ('PCA', PCA(whiten=True, n_components=30)),\n",
    "#                     ('clf', SequentialClassifier(LogisticRegressionCV(cv=5, max_iter=200)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[{'description': x[1], 'value': round(x[2] * 100)} \n",
    "#                     for x in results['top_edits']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "predictions = []\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train = revisions.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = revisions.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    cv_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred = cv_fit.predict(X_test)\n",
    "    predictions.append(pd.DataFrame({'actual': y_test, 'pred': y_pred}))\n",
    "\n",
    "predictions = pd.concat(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for the accuracy, average the number of correct binary classifications each observation, then average over all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989452257586973"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(predictions['actual'].cat.categories)\n",
    "np.mean(1 - np.abs(predictions['actual'].cat.codes - predictions['pred'].cat.codes) / (n_classes - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = predictions.groupby(['actual', 'pred']).aggregate(len).reset_index()\n",
    "confusion = confusion.rename(columns={0: 'n'})\n",
    "confusion['p'] = confusion['n'] / confusion['n'].sum()\n",
    "actual_totals = confusion.groupby(['actual'])['n'].transform('sum')\n",
    "confusion['p_actual'] = confusion['n'] / actual_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table = confusion.pivot(index='actual', columns='pred', values='p_actual').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_table, vmin=0, vmax=1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig('confusion-matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree of the Ordinal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphic of the tree of the ordinal model used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\troot [label=\"\"]\n",
      "\tstub [label=\"P(Stub)\"]\n",
      "\tgtstub [label=\"P(x > Stub\"]\n",
      "\tstart [label=\"P(Start)\"]\n",
      "\tgtstart [label=\"P(x > Start)\"]\n",
      "\tc [label=\"P(C)\"]\n",
      "\tgtc [label=\"P(x > C)\"]\n",
      "\tb [label=\"P(B)\"]\n",
      "\tgtb [label=\"P(x > B)\"]\n",
      "\tga [label=\"P(GA)\"]\n",
      "\tfa [label=\"P(FA)\"]\n",
      "\troot -> stub\n",
      "\troot -> gtstub\n",
      "\tgtstub -> start\n",
      "\tgtstub -> gtstart\n",
      "\tgtstart -> c\n",
      "\tgtstart -> gtc\n",
      "\tgtc -> b\n",
      "\tgtc -> gtb\n",
      "\tgtb -> ga\n",
      "\tgtb -> fa\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dot = Digraph(format='png')\n",
    "dot.node('root', '')\n",
    "dot.node('stub', 'P(Stub)')\n",
    "dot.node('gtstub', 'P(x > Stub')\n",
    "dot.node('start', 'P(Start)')\n",
    "dot.node('gtstart', 'P(x > Start)')\n",
    "dot.node('c', 'P(C)')\n",
    "dot.node('gtc', 'P(x > C)')\n",
    "dot.node('b', 'P(B)')\n",
    "dot.node('gtb', 'P(x > B)')\n",
    "dot.node('ga', 'P(GA)')\n",
    "dot.node('fa', 'P(FA)')\n",
    "dot.edges([['root', 'stub'], \n",
    "           ['root', 'gtstub'],\n",
    "           ['gtstub', 'start'],\n",
    "           ['gtstub', 'gtstart'],\n",
    "           ['gtstart', 'c'],\n",
    "           ['gtstart', 'gtc'],\n",
    "           ['gtc', 'b'],\n",
    "           ['gtc', 'gtb'],\n",
    "           ['gtb', 'ga'],\n",
    "           ['gtb', 'fa']            \n",
    "          ])\n",
    "print(dot.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.gv.png'"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.render('model.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wp10\n",
       "Stub     5486\n",
       "Start    5476\n",
       "C        5485\n",
       "B        5486\n",
       "GA       5495\n",
       "FA       4996\n",
       "Name: wp10, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions.groupby('wp10')['wp10'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'clf__estimator__min_child_weight': list(range(1, 11)),\n",
    "    'clf__estimator__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'clf__estimator__subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'clf__estimator__colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'clf__estimator__max_depth': [2, 3, 4, 5, 6, 7, 8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf__estimator__subsample': 0.8,\n",
       "  'clf__estimator__min_child_weight': 2,\n",
       "  'clf__estimator__max_depth': 6,\n",
       "  'clf__estimator__gamma': 1,\n",
       "  'clf__estimator__colsample_bytree': 0.7},\n",
       " {'clf__estimator__subsample': 0.7,\n",
       "  'clf__estimator__min_child_weight': 4,\n",
       "  'clf__estimator__max_depth': 8,\n",
       "  'clf__estimator__gamma': 1.5,\n",
       "  'clf__estimator__colsample_bytree': 1.0},\n",
       " {'clf__estimator__subsample': 0.8,\n",
       "  'clf__estimator__min_child_weight': 5,\n",
       "  'clf__estimator__max_depth': 6,\n",
       "  'clf__estimator__gamma': 5,\n",
       "  'clf__estimator__colsample_bytree': 0.5},\n",
       " {'clf__estimator__subsample': 0.5,\n",
       "  'clf__estimator__min_child_weight': 6,\n",
       "  'clf__estimator__max_depth': 2,\n",
       "  'clf__estimator__gamma': 2,\n",
       "  'clf__estimator__colsample_bytree': 0.6},\n",
       " {'clf__estimator__subsample': 1.0,\n",
       "  'clf__estimator__min_child_weight': 5,\n",
       "  'clf__estimator__max_depth': 2,\n",
       "  'clf__estimator__gamma': 1,\n",
       "  'clf__estimator__colsample_bytree': 1.0}]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ParameterSampler(xgb_param_grid, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "take_nd() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/jrnold/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 420, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/Users/jrnold/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 563, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/jrnold/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 261, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/jrnold/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 261, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/jrnold/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 518, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"/Users/jrnold/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 206, in _safe_split\n    y_subset = safe_indexing(y, indices)\n  File \"/Users/jrnold/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 185, in safe_indexing\n    return X.take(indices, axis=0)\nTypeError: take_nd() got an unexpected keyword argument 'axis'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-518-73dbe4689ca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 **rnd_search_pars)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: take_nd() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "#X = create_features(revisions)\n",
    "\n",
    "rnd_search_pars = {'n_iter': 2, 'n_jobs': 3, 'cv': 2}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(pipeline, xgb_param_grid, scoring='neg_log_loss',\n",
    "                                random_state=1234, refit=True,\n",
    "                                **rnd_search_pars)\n",
    "rnd_search.fit(revisions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "prob_pred = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[cat] = {\n",
    "    'f1': f1_score(y_test, y_pred),\n",
    "    'recall_score': recall_score(y_test, y_pred),\n",
    "    'precision_score': precision_score(y_test, y_pred),\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "    'roc_auc_score': roc_auc_score(y_test, y_pred),\n",
    "    'log_loss': log_loss(y_test, prob_pred)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding best parameter values for all models, refit using the entire sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionCV' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-611-13b10fb945ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_estimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Feature importance for {cat}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionCV' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for cat, model in model.named_steps['clf'].named_estimators_.items():\n",
    "    xgb.plot_importance(model)\n",
    "    plt.title(f\"Feature importance for {cat}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=200,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.mw import get_page, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 171\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 180\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, params, files, auth)\u001b[0m\n\u001b[1;32m    100\u001b[0m                                         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                                         auth=auth)\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f5ccea616405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data science\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/insight/wikidit/wikidit/mw.py\u001b[0m in \u001b[0;36mget_page\u001b[0;34m(session, title)\u001b[0m\n\u001b[1;32m     99\u001b[0m               \u001b[0;34m'redirects'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m               'rvprop': 'ids|content|timestamp', \"rvslots\": \"main\"}\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# There is no such page!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, query_continue, auth, continuation, **params)\u001b[0m\n\u001b[1;32m    307\u001b[0m         return self.request('GET', params=params, auth=auth,\n\u001b[1;32m    308\u001b[0m                             \u001b[0mquery_continue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_continue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                             continuation=continuation)\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     def post(self, query_continue=None, upload_file=None, auth=None,\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, params, query_continue, files, auth, continuation)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             return self._request(method, params=normal_params, auth=auth,\n\u001b[0;32m--> 171\u001b[0;31m                                  files=files)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     def continuation(self, method, params=None, query_continue=None,\n",
      "\u001b[0;32m~/anaconda3/envs/wikidit/lib/python3.6/site-packages/mwapi/session.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, params, files, auth)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?action=query&titles=Data+science&prop=revisions&redirects=True&rvprop=ids%7Ccontent%7Ctimestamp&rvslots=main&format=json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0xa22aa4d30>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "page = get_page(session, \"Data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.preprocessing import Featurizer\n",
    "featurizer = Featurizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized = featurizer.featurize(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import predict_page_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"../models/xgboost-sequential.pkl\", \"rb\") as f:\n",
    "    MODEL = dill.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Data science\"\n",
    "# session = Session()\n",
    "# page = get_page(session, title)\n",
    "# result = predict_page_edits(featurizer, page['content'], MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import qual_score, make_edits\n",
    "content = page['content']\n",
    "featurizer = Featurizer()\n",
    "model = MODEL\n",
    "revision = featurizer.parse_content(content)\n",
    "del revision['text']\n",
    "revision = pd.DataFrame.from_records([revision])\n",
    "# revision = create_features(revision)\n",
    "\n",
    "# probabilities for current class\n",
    "prob = model.predict_proba(revision)\n",
    "best = str(model.predict(revision)[0])\n",
    "score = qual_score(prob)\n",
    "\n",
    "# Calc new probabilities for all types of edits\n",
    "edits = [(nm, description, pd.DataFrame.from_records([x])) \n",
    "         for nm, x, description in make_edits(revision.to_dict('records')[0])]\n",
    "edit_probs = [(nm, description, model.predict_proba(ed)) for nm, description, ed in edits]\n",
    "edit_scores = [(nm, description, qual_score(p)) for nm, description, p in edit_probs]\n",
    "edit_changes = [(n, d, s - score) for n, d, s in edit_scores]\n",
    "top_edits = sorted([x for x in edit_changes if x[2] > 0], key=lambda x: -x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.26, 0.26, 0.37, 0.1 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.round(prob, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('infoboxes',\n",
       "  '<a href=\"https://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Infoboxes\">Add an infobox</a>',\n",
       "  0.40727842903825273),\n",
       " ('words', 'Add a sentence (15 words)', 0.023514236413411993)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['top_edits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words\n",
      "headings\n",
      "sub_headings\n",
      "images\n",
      "categories\n",
      "wikilinks\n",
      "external_links\n",
      "citation\n",
      "ref\n",
      "coordinates\n",
      "infoboxes\n",
      "backlog_accuracy\n",
      "backlog_other\n",
      "backlog_style\n",
      "backlog_links\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edits:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   words  infoboxes  ref\n",
      "0   1887          0   60\n",
      "   words  infoboxes  ref\n",
      "0   1875          0   60\n",
      "   words  infoboxes  ref\n",
      "0   1872       True   60\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edits:\n",
    "    if w in ('words', 'infoboxes', 'ref'):\n",
    "        print(data.loc[:, ['words', 'infoboxes', 'ref']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.25 0.27 0.38 0.1 ]]\n",
      "[[0.   0.   0.17 0.1  0.56 0.16]]\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edit_probs:\n",
    "    if w in ('words', 'infoboxs'):\n",
    "        print(np.round(data, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32\n",
      "4.7\n"
     ]
    }
   ],
   "source": [
    "for w, d, data in edit_scores:\n",
    "    if w in ('words', 'infoboxes'):\n",
    "        print(np.round(data, 2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.29364713400031"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41000000000000014"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.7 - 4.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03000000000000025"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.32 - 4.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backlog_accuracy</th>\n",
       "      <th>backlog_accuracy_templates</th>\n",
       "      <th>backlog_content</th>\n",
       "      <th>backlog_content_templates</th>\n",
       "      <th>backlog_files</th>\n",
       "      <th>backlog_files_templates</th>\n",
       "      <th>backlog_links</th>\n",
       "      <th>backlog_links_templates</th>\n",
       "      <th>backlog_other</th>\n",
       "      <th>backlog_other_templates</th>\n",
       "      <th>...</th>\n",
       "      <th>ref_per_word</th>\n",
       "      <th>smartlists</th>\n",
       "      <th>smartlists_per_word</th>\n",
       "      <th>sub_headings</th>\n",
       "      <th>sub_headings_per_word</th>\n",
       "      <th>templates</th>\n",
       "      <th>templates_per_word</th>\n",
       "      <th>wikilinks</th>\n",
       "      <th>wikilinks_per_word</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>84</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   backlog_accuracy backlog_accuracy_templates  backlog_content  \\\n",
       "0                 0                       None                0   \n",
       "\n",
       "  backlog_content_templates  backlog_files backlog_files_templates  \\\n",
       "0                      None              0                    None   \n",
       "\n",
       "   backlog_links backlog_links_templates  backlog_other  \\\n",
       "0              0                    None              0   \n",
       "\n",
       "  backlog_other_templates  ...    ref_per_word smartlists  \\\n",
       "0                    None  ...        0.032051          0   \n",
       "\n",
       "   smartlists_per_word  sub_headings  sub_headings_per_word  templates  \\\n",
       "0                  0.0             0                    0.0         42   \n",
       "\n",
       "   templates_per_word  wikilinks  wikilinks_per_word  words  \n",
       "0            0.022436         84            0.044872   1872  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidit.models import make_edits, add_per_word, add_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
