{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwparserfromhell as mwparser\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwapi\n",
    "session = mwapi.Session(\"https://en.wikipedia.org\", user_agent=\"<jeffrey.arnold@gmail.com>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = session.get(action=\"query\", titles=\"Data science\", prop='revisions', rvprop='content', rvslots='main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(rev['query']['pages'].values())[0]['revisions'][0]['slots']['main']['*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[[Category:Information science]]',\n",
       " '[[Category:Computer occupations]]',\n",
       " '[[Category:Computational fields of study]]',\n",
       " '[[Category:Data analysis]]']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = mwparser.parse(text)\n",
    "list(parsed.ifilter_wikilinks(matches=\"Category:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_template_name(x):\n",
    "    return str(x.name).lower().strip().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    \n",
    "def is_image(x):\n",
    "    _RE_IMAGE = re.compile('^(?:File|Image|Media):', flags=re.I)    \n",
    "    return _RE_IMAGE.match(str(x.title))\n",
    "\n",
    "def get_images(x):\n",
    "    for cat in x.ifilter_wikilinks():\n",
    "        if is_image(x):\n",
    "            yield x\n",
    "\n",
    "def is_category(x):\n",
    "    _RE_CATEGORY = re.compile('^Category:', flags=re.I)\n",
    "    return _RE_CATEGORY.match(str(x.title))\n",
    "\n",
    "def get_categories(x):\n",
    "    for cat in x.ifilter_wikilinks():\n",
    "        if is_category(x):\n",
    "            yield x\n",
    "            \n",
    "def is_ref(x):\n",
    "    if is_tag(x, \"ref$\"):\n",
    "        return True\n",
    "    if is_template(x, pattern=\"(ref|note)$\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_tag(x, pattern=None):\n",
    "    out = isinstance(x, mwparser.nodes.Tag)\n",
    "    if out and pattern is not None:\n",
    "        out = re.match(pattern, str(x.tag), re.I)\n",
    "    return out\n",
    "\n",
    "def is_heading(x):\n",
    "    return isinstance(x, mwparser.nodes.Heading)\n",
    "\n",
    "def is_wikilink(x):\n",
    "    return isinstance(x, mwparser.nodes.Wikilink)\n",
    "\n",
    "def is_template(x, pattern=None):\n",
    "    out = isinstance(x, mwparser.nodes.Template)\n",
    "    if out and pattern is not None:\n",
    "        out = re.match(pattern, clean_template_name(x), re.I)\n",
    "    return out\n",
    "\n",
    "class WikicodeConverter:\n",
    " \n",
    "    def __init__(self, parser = mwparser.parser.Parser(), tags_keep=[], tags_remove=[],\n",
    "                 templates_keep=[], templates_remove=[], headings_remove=[]):\n",
    "        self._parser = parser\n",
    "        self.tags_keep = tags_keep\n",
    "        self.tags_remove = tags_remove\n",
    "        self.templates_keep = templates_keep\n",
    "        self.templates_remove = templates_remove\n",
    "        self.headings_remove = headings_remove\n",
    "      \n",
    "    def _strip_tag(self, x):\n",
    "        tag = x.tag.lower().strip()\n",
    "        if tag in self.tags_keep:\n",
    "            out = f\"<{tag.tag}>\"\n",
    "        elif tag in self.tags_remove:\n",
    "            out = None\n",
    "        else:\n",
    "            out = x.__strip__()\n",
    "        return out\n",
    "    \n",
    "    def _strip_template(self, x):\n",
    "        name = clean_template_name(x)\n",
    "        if (self.templates_keep and \n",
    "            re.match('|'.join(self.templates_keep), name)):\n",
    "            out = \"{{\" + name + \"}}\"\n",
    "        elif re.match(\"|\".join(self.templates_remove), name):\n",
    "            out = None\n",
    "        else:\n",
    "            out = x.__strip__()\n",
    "        return out    \n",
    "    \n",
    "    def _span(self, i, text, label=None):\n",
    "        if text is None:\n",
    "            start = max(0, i - 1)\n",
    "            end = max(1, i)\n",
    "        else:\n",
    "            start = i\n",
    "            end = len(text)\n",
    "        return {'start': start, 'end': end, 'label': label}\n",
    "    \n",
    "    def convert(self, content):\n",
    "        \"\"\"Convert Wiki markup to plain text.\"\"\"\n",
    "        wikicode = mwparser.parse(content)\n",
    "        texts = []\n",
    "        references = []\n",
    "        templates = []\n",
    "        # then concatenate the stripped text of each section\n",
    "        tok = 0\n",
    "        for i, section in enumerate(wikicode.get_sections(flat=True, include_lead=True, include_headings=True)):\n",
    "            # ignore headers\n",
    "            headings = section.filter_headings()\n",
    "            if len(headings) and str(headings[0].title).strip().lower() in self.headings_remove:\n",
    "                continue\n",
    "            for node in section.nodes:\n",
    "                nodestr = None\n",
    "                # references needs to preceed tags and templates since they\n",
    "                # have both forms\n",
    "                if is_ref(node):\n",
    "                    nodestr = \" \"\n",
    "                    references.append(tok)\n",
    "                elif is_tag(node):\n",
    "                    if str(node.tag).lower() in (\"table\", \"img\"):\n",
    "                        nodestr = None       \n",
    "                    else:\n",
    "                        nodestr = self._strip_tag(node)\n",
    "                elif is_template(node):\n",
    "                    nodestr = self._strip_template(node)\n",
    "                    if nodestr is None or not len(nodestr):\n",
    "                        nodestr = \" \"\n",
    "                    templates.append(self._span(tok, nodestr, clean_template_name(node)))\n",
    "                elif is_category(node) or is_image(node):\n",
    "                    pass\n",
    "                elif is_heading(node):\n",
    "                    nodestr = None\n",
    "                else:\n",
    "                    nodestr = str(node.__strip__(normalize=True))\n",
    "                if nodestr is not None:\n",
    "                    tok += len(nodestr)\n",
    "                    texts.append(nodestr)\n",
    "        return {'text': ''.join(texts), 'references': references, 'templates': templates}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_keep = []\n",
    "converter = WikicodeConverter(tags_remove=[\"img\", \"table\"],\n",
    "                              templates_remove=[\"infobox\", \"reflist\", \"notelist\"],\n",
    "                              headings_remove=[\"see also\", \"bibliography\", \"references\", \"external links\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = converter.convert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(cleaned['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "\n",
    "Token.set_extension('reference', default=False, force=True)\n",
    "references = cleaned['references']\n",
    "for tok in reversed(doc):\n",
    "    if len(references) and not tok.is_space and tok.idx <= references[-1]:\n",
    "        # this is needed to handle multiple references\n",
    "        while len(references) and tok.idx <= references[-1]:\n",
    "            references.pop()\n",
    "        tok._.set('reference', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". True\n",
      ". True\n",
      ", True\n",
      ", True\n",
      "\" True\n",
      ". True\n",
      "\" True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ", True\n",
      ". True\n",
      "\" True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ") True\n",
      ", True\n",
      ". True\n",
      ", True\n",
      "\" True\n",
      "method True\n",
      "\" True\n",
      ", True\n",
      "Analytics True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      "Analytics True\n",
      ". True\n",
      ". True\n",
      "â€ True\n",
      "advantage True\n",
      ". True\n",
      ". True\n",
      ", True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ", True\n",
      ", True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      ". True\n",
      "\" True\n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    if tok._.get('reference'):\n",
    "        print(tok, tok._.get('reference'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cleaned['references']:\n",
    "    print(i, [tok for tok in doc if tok.idx <= i and not tok.is_whitespace][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.is_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tok for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
